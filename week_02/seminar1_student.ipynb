{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seminar: Spectrogram Madness\n",
    "\n",
    "![img](https://github.com/yandexdataschool/speech_course/raw/main/week_02/stft-scheme.jpg)\n",
    "\n",
    "#### Today you're finally gonna deal with speech! We'll walk you through all the main steps of speech processing pipeline and you'll get to do voice-warping. It's gonna be fun! ....and creepy. Very creepy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "display(Audio(\"sample1.wav\"))\n",
    "display(Audio(\"sample2.wav\"))\n",
    "display(Audio(\"welcome.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes, sample_rate = librosa.core.load(\"sample1.wav\")\n",
    "\n",
    "display(Audio(amplitudes, rate=sample_rate))\n",
    "print(sample_rate)\n",
    "\n",
    "print(\"Length: {} seconds at sample rate {}\".format(amplitudes.shape[0] / sample_rate, sample_rate))\n",
    "plt.figure(figsize=[16, 4])\n",
    "plt.title(\"First 10^4 out of {} amplitudes\".format(len(amplitudes)))\n",
    "plt.plot(amplitudes[:10000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Mel-Spectrogram (5 points)\n",
    "\n",
    "As you can see, amplitudes follow a periodic patterns with different frequencies. However, it is very difficult to process these amplitudes directly because there's so many of them! A typical WAV file contains 22050 amplitudes per second, which is already way above a typical sequence length for other NLP applications. Hence, we need to compress this information to something manageable. \n",
    "\n",
    "A typical solution is to use __spectrogram:__ instead of saving thousands of amplitudes, we can perform Fourier transformation to find which periodics are prevalent at each point in time. More formally, a spectrogram applies [Short-Time Fourier Transform (STFT)](https://en.wikipedia.org/wiki/Short-time_Fourier_transform) to small overlapping windows of the amplitude time-series:\n",
    "\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Phillip_Lobel/publication/267827408/figure/fig2/AS:295457826852866@1447454043380/Spectrograms-and-Oscillograms-This-is-an-oscillogram-and-spectrogram-of-the-boatwhistle.png\" width=\"480px\">\n",
    "\n",
    "However, this spectrogram may have extraordinarily large numbers that can break down neural networks. Therefore the standard approach is to convert spectrogram into a __mel-spectrogram__ by changing frequencies to [Mel-frequency spectrum](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum).\n",
    "\n",
    "Hence, the algorithm to compute spectrogram of amplitudes $y$ becomes:\n",
    "1. Compute Short-Time Fourier Transform (STFT): apply fourier transform to overlapping windows\n",
    "2. Build a spectrogram: $S_{ij} = abs(STFT(y)_{ij}^2)$\n",
    "3. Convert spectrogram to a Mel basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helpers:\n",
    "# 1. slice time-series into overlapping windows\n",
    "def slice_into_frames(amplitudes, window_length, hop_length):\n",
    "    return librosa.core.spectrum.util.frame(\n",
    "        np.pad(amplitudes, int(window_length // 2), mode='reflect'),\n",
    "        frame_length=window_length, hop_length=hop_length)\n",
    "    # output shape: [window_length, num_windows]\n",
    "\n",
    "dummy_amps = amplitudes[2048: 6144]\n",
    "dummy_frames = slice_into_frames(dummy_amps, 2048, 512)\n",
    "print(amplitudes.shape)\n",
    "\n",
    "plt.figure(figsize=[16, 4])\n",
    "plt.subplot(121, title='Whole audio sequence', ylim=[-3, 3])\n",
    "plt.plot(dummy_amps)\n",
    "\n",
    "plt.subplot(122, title='Overlapping frames', yticks=[])\n",
    "for i, frame in enumerate(dummy_frames.T):\n",
    "    plt.plot(frame + 10 - i);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Weights for window transform. Before performing FFT you can scale amplitudes by a set of weights\n",
    "# The weights we're gonna use are large in the middle of the window and small on the sides\n",
    "dummy_window_length = 3000\n",
    "dummy_weights_window = librosa.core.spectrum.get_window('hann', dummy_window_length, fftbins=True)\n",
    "plt.plot(dummy_weights_window); plt.plot([1500, 1500], [0, 1.1], label='window center'); plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fast Fourier Transform in Numpy. Note: this function can process several inputs at once (mind the axis!)\n",
    "dummy_fft = np.fft.rfft(dummy_amps[:3000, None] * dummy_weights_window[:, None], axis=0)  # complex[sequence_length, num_sequences]\n",
    "plt.plot(np.real(dummy_fft)[:, 0])\n",
    "print(dummy_fft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now it's time to combine everything into a __S__hort-__T__ime __F__ourier __T__ransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STFT(amplitudes, window_length, hop_length):\n",
    "    \"\"\" Compute short-time Fourier Transform \"\"\"\n",
    "    # slice amplitudes into overlapping frames [window_length, num_frames]\n",
    "    frames = slice_into_frames(amplitudes, window_length, hop_length)\n",
    "    \n",
    "    # get weights for fourier transform, float[window_length]\n",
    "    weights_window = <YOUR CODE>\n",
    "   \n",
    "    \n",
    "    # apply fourier transfrorm to frames scaled by weights\n",
    "    stft = <YOUR CODE>\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = get_STFT(amplitudes, window_length=2048, hop_length=512)\n",
    "plt.plot(abs(stft)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(amplitudes, sample_rate=22050, n_mels=128,\n",
    "                       window_length=2048, hop_length=512, fmin=1, fmax=8192):\n",
    "    \"\"\"\n",
    "    Implement mel-spectrogram as described above.\n",
    "    :param amplitudes: float [num_amplitudes], time-series of sound amplitude, same as above\n",
    "    :param sample rate: num amplitudes per second\n",
    "    :param n_mels: spectrogram channels\n",
    "    :param window_length: length of a patch to which you apply FFT\n",
    "    :param hop_length: interval between consecutive windows\n",
    "    :param f_min: minimal frequency\n",
    "    :param f_max: maximal frequency\n",
    "    :returns: mel-spetrogram [n_mels, duration]\n",
    "    \"\"\"\n",
    "    # Step I: compute Short-Time Fourier Transform\n",
    "    stft = <YOUR CODE>\n",
    "    assert stft.shape == (window_length // 2 + 1, len(amplitudes) // hop_length + 1)\n",
    "    \n",
    "    # Step II: convert stft to a spectrogram\n",
    "    spectrogram = <YOUR CODE>\n",
    "    \n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Mel Basis\n",
    "\n",
    "The Mel-scale is a perceptual scale which represents how sensitive humans are to various sounds. We will use it to compress and transform our spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_basis = librosa.filters.mel(22050, n_fft=2048,\n",
    "                                    n_mels=128, fmin=1, fmax=8192)\n",
    "plt.figure(figsize=[16, 10])\n",
    "plt.title(\"Mel Basis\"); plt.xlabel(\"Frequence\"); plt.ylabel(\"Mel-Basis\")\n",
    "plt.imshow(np.log(mel_basis),origin='lower', cmap=plt.cm.hot,interpolation='nearest', aspect='auto')\n",
    "plt.colorbar(use_gridspec=True)\n",
    "\n",
    "# Can \n",
    "mat= np.matmul(mel_basis.T, mel_basis)\n",
    "\n",
    "plt.figure(figsize=[16, 10])\n",
    "plt.title(\"recovered frequence Basis\"); plt.xlabel(\"Frequence\"); plt.ylabel(\"Frequency\")\n",
    "plt.imshow(np.log(mat),origin='lower', cmap=plt.cm.hot,interpolation='nearest', aspect='auto')\n",
    "plt.colorbar(use_gridspec=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram(amplitudes, sample_rate=22050, n_mels=128,\n",
    "                       window_length=2048, hop_length=512, fmin=1, fmax=8192):\n",
    "    spectrogram = get_spectrogram(amplitudes, sample_rate=sample_rate, n_mels=n_mels,\n",
    "                       window_length=window_length, hop_length=hop_length, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    # Step III: convert spectrogram into Mel basis (multiplying by transformation matrix)\n",
    "    mel_basis = librosa.filters.mel(sample_rate, n_fft=window_length,\n",
    "                                    n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "    # -- matrix [n_mels, window_length / 2 + 1]\n",
    "    \n",
    "    mel_spectrogram = <YOUR_CODE>\n",
    "    assert mel_spectrogram.shape == (n_mels, len(amplitudes) // hop_length + 1)\n",
    "    \n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes1, s1 = librosa.core.load(\"./sample1.wav\")\n",
    "amplitudes2, s2 = librosa.core.load(\"./sample2.wav\")\n",
    "print(s1)\n",
    "ref1 = librosa.feature.melspectrogram(amplitudes1, sr=sample_rate, n_mels=128, fmin=1, fmax=8192)\n",
    "ref2 = librosa.feature.melspectrogram(amplitudes2, sr=sample_rate, n_mels=128, fmin=1, fmax=8192)\n",
    "assert np.allclose(get_melspectrogram(amplitudes1), ref1, rtol=1e-4, atol=1e-4)\n",
    "assert np.allclose(get_melspectrogram(amplitudes2), ref2, rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"That's no moon - it's a space station!\"); plt.xlabel(\"Time\"); plt.ylabel(\"Frequency\")\n",
    "plt.imshow(np.log10(get_melspectrogram(amplitudes1)),origin='lower', vmin=-10, vmax=5, cmap=plt.cm.hot)\n",
    "plt.colorbar(use_gridspec=True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Help me, Obi Wan Kenobi. You're my only hope.\"); plt.xlabel(\"Time\"); plt.ylabel(\"Frequency\")\n",
    "plt.imshow(np.log10(get_melspectrogram(amplitudes2)),origin='lower', vmin=-10, vmax=5, cmap=plt.cm.hot);\n",
    "plt.colorbar(use_gridspec=True)\n",
    "\n",
    "# note that the second spectrogram has higher mean frequency corresponding to the difference in gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Griffin-Lim Algorithm - 5 Points\n",
    "\n",
    "\n",
    "In this task you are going to reconstruct the original audio signal from a spectrogram using the __Griffin-Lim Algorithm (GLA)__ . The Griffin-Lim Algorithm is a phase reconstruction method based on the redundancy of the short-time Fourier transform. It promotes the consistency of a spectrogram by iterating two projections, where a spectrogram is said to be consistent when its inter-bin dependency owing to the redundancy of STFT is retained. GLA is based only on the consistency and does not take any prior knowledge about the target signal into account.\n",
    "\n",
    "\n",
    "This algorithm expects to recover a __complex-valued spectrogram__, which is consistent and maintains the given amplitude $\\mathbf{A}$, by the following alternative projection procedure. Initialize a random \"reconstruced\" signal $\\mathbf{x}$, and obtain it's STFT\n",
    "$$\\mathbf{X} = \\text{STFT}(\\mathbf{x})$$\n",
    "\n",
    "Then we __discard__ the magnitude of $\\mathbf{X}$ and keep only a random phase $\\mathbf{\\phi}$. Using the phase and the given magnitude $\\mathbf{A}$ we construct a new complex value spectrogram $ \\mathbf{\\tilde X}$ using the euler equation\n",
    "\n",
    "$$\\mathbf{\\tilde X} = \\mathbf{A}\\cdot e^{j\\mathbf{\\phi}}$$\n",
    "\n",
    "Then we reconstruct the signal $\\mathbf{\\tilde x}$ using an __inverse STFT__:\n",
    "\n",
    "$$\\mathbf{\\tilde x} = \\text{iSTFT}(\\mathbf{\\tilde X})$$\n",
    "\n",
    "We update our value of the signal reconstruction:\n",
    "\n",
    "$$ \\mathbf{x} = \\mathbf{\\tilde x} $$\n",
    "\n",
    "Finally, we interate this procedure multiple times and return the final $$\\mathbf{x}$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Reconstruct your Spectrogram from the Mel-Spectrogram\n",
    "def inv_mel_spectrogram(mel_spectrogram, sample_rate=22050, n_mels=128,\n",
    "                       window_length=2048, hop_length=512, fmin=1, fmax=8192):\n",
    "    \n",
    "    mel_basis = librosa.filters.mel(sample_rate, n_fft=window_length,\n",
    "                                    n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    inv_mel_basis = <INSERT YOUR CODE>\n",
    "    spectrogram = <INSERT YOUT CODE>\n",
    "    \n",
    "    \n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes, sample_rate = librosa.core.load(\"welcome.wav\")\n",
    "display(Audio(amplitudes, rate=sample_rate))\n",
    "\n",
    "\n",
    "true_spec = get_spectrogram(amplitudes)\n",
    "mel_spec = get_melspectrogram(amplitudes, window_length=2048, hop_length=512)\n",
    "\n",
    "#!!! Here you can modify your Mel-Spectrogram. Let your twisted imagination fly wild here !!!\n",
    "\n",
    "#mel_spec[40:50,:]=0 # Zero out some freqs\n",
    "\n",
    "# mel_spec[10:124,:] = mel_spec[0:114,:] # #Pitch-up \n",
    "# mel_spec[0:10,:]=0 \n",
    "\n",
    "# mel_spec[0:114,:] = mel_spec[10:124,:] # #Pitch-down \n",
    "# mel_spec[114:124,:]=0\n",
    "\n",
    "#mel_spec[:,:] = mel_spec[:,::-1] #Time reverse\n",
    "\n",
    "#mel_spec[64:,:] = mel_spec[:64,:] # Trippy Shit\n",
    "\n",
    "#mel_spec[:,:] = mel_spec[::-1,:] # Aliens are here\n",
    "\n",
    "#mel_spec[64:,:] = mel_spec[:64,:] # Trippy Shit\n",
    "\n",
    "#mel_spec[:,:] = mel_spec[::-1,::-1] # Say hello to your friendly neighborhood Chaos God\n",
    "\n",
    "#!!! END MADNESS !!!\n",
    "\n",
    "\n",
    "#Convert Back to Spec\n",
    "spec = inv_mel_spectrogram(mel_spec, window_length=2048, hop_length=512)\n",
    "\n",
    "scale_1 = 1.0 / np.amax(mel_spec)\n",
    "\n",
    "scale_1 = 1.0 / np.amax(true_spec)\n",
    "scale_2 = 1.0 / np.amax(spec)\n",
    "\n",
    "plt.figure(figsize=[16, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Welcome...!\"); plt.xlabel(\"Time\"); plt.ylabel(\"Frequency\")\n",
    "plt.imshow((true_spec*scale_1)**0.125,origin='lower',interpolation='nearest', cmap=plt.cm.hot, aspect='auto')\n",
    "plt.colorbar(use_gridspec=True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Xkdfsas...!\"); plt.xlabel(\"Time\"); plt.ylabel(\"Frequency\")\n",
    "plt.imshow((spec*scale_2)**0.125,origin='lower',interpolation='nearest', cmap=plt.cm.hot, aspect='auto')\n",
    "plt.colorbar(use_gridspec=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[16, 10])\n",
    "plt.title(\"Xkdfsas...!\"); plt.xlabel(\"Time\"); plt.ylabel(\"Frequency\")\n",
    "plt.imshow((mel_spec**0.125),origin='lower',interpolation='nearest', cmap=plt.cm.hot, aspect='auto')\n",
    "plt.colorbar(use_gridspec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets examine how to take an inverse FFT\n",
    "dummy_window_length = 3000\n",
    "dummy_weights_window = librosa.core.spectrum.get_window('hann', dummy_window_length, fftbins=True)\n",
    "\n",
    "dummy_fft = np.fft.rfft(dummy_amps[:3000, None] * dummy_weights_window[:, None], axis=0)  # complex[sequence_length, num_sequences]\n",
    "print(dummy_fft.shape)\n",
    "rec_dummy_amps = dummy_weights_window*np.real(np.fft.irfft(dummy_fft[:,0]))\n",
    "plt.plot(dummy_amps[:3000])\n",
    "plt.plot(rec_dummy_amps[:3000])\n",
    "plt.legend(['Original', 'Reconstructed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step II: Reconstruct amplitude samples from STFT\n",
    "def get_iSTFT(spectrogram, window_length, hop_length):\n",
    "    \"\"\" Compute inverse short-time Fourier Transform \"\"\"\n",
    "    \n",
    "    # get weights for fourier transform, float[window_length]\n",
    "    window = librosa.core.spectrum.get_window('hann', window_length, fftbins=True)\n",
    "    \n",
    "    time_slices = spectrogram.shape[1]\n",
    "    len_samples = int(time_slices*hop_length+window_length)\n",
    "    \n",
    "    x = np.zeros(len_samples)\n",
    "    # apply inverse fourier transfrorm to frames scaled by weights and save into x\n",
    "    amplitudes = <YOUR CODE>\n",
    "        \n",
    "    # Trim the array to correct length from both sides\n",
    "    x = <YOUR_CODE>\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step III: Implement the Griffin-Lim Algorithm\n",
    "def griffin_lim(power_spectrogram, window_size, hop_length, iterations, seed=1, verbose=True):\n",
    "    \"\"\"Reconstruct an audio signal from a magnitude spectrogram.\n",
    "    Given a power spectrogram as input, reconstruct\n",
    "    the audio signal and return it using the Griffin-Lim algorithm from the paper:\n",
    "    \"Signal estimation from modified short-time fourier transform\" by Griffin and Lim,\n",
    "    in IEEE transactions on Acoustics, Speech, and Signal Processing. Vol ASSP-32, No. 2, April 1984.\n",
    "    Args:\n",
    "        power_spectrogram (2-dim Numpy array): The power spectrogram. The rows correspond to the time slices\n",
    "            and the columns correspond to frequency bins.\n",
    "        window_size (int): The FFT size, which should be a power of 2.\n",
    "        hop_length (int): The hope size in samples.\n",
    "        iterations (int): Number of iterations for the Griffin-Lim algorithm. Typically a few hundred\n",
    "            is sufficient.\n",
    "    Returns:\n",
    "        The reconstructed time domain signal as a 1-dim Numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_slices = power_spectrogram.shape[1]\n",
    "    len_samples = int(time_slices*hop_length-hop_length)\n",
    "    \n",
    "    # Obtain STFT magnitude from Spectrogram\n",
    "\n",
    "    magnitude_spectrogram = <YOUR CODE>\n",
    "    \n",
    "    # Initialize the reconstructed signal to noise.\n",
    "    np.random.seed(seed)\n",
    "    x_reconstruct = np.random.randn(len_samples)\n",
    "    \n",
    "    for n in range(iterations):\n",
    "        # Get the SFTF of a random signal\n",
    "        reconstruction_spectrogram = <YOUR_CODE>\n",
    "        \n",
    "        # Obtain the angle part of random STFT. Hint: unit np.angle\n",
    "        reconstruction_angle = <YOUR_CODE>\n",
    "        \n",
    "        # Discard magnitude part of the reconstruction and use the supplied magnitude spectrogram instead.\n",
    "        proposal_spectrogram = <YOUR_CODE>\n",
    "        assert proposal_spectrogram.dtype == np.complex\n",
    "        \n",
    "        \n",
    "        # Save previous construction\n",
    "        prev_x = x_reconstruct\n",
    "        \n",
    "        # Reconstruct signal\n",
    "        x_reconstruct = <YOUR CODE>\n",
    "        \n",
    "        # Measure RMSE\n",
    "        diff = np.sqrt(sum((x_reconstruct - prev_x)**2)/x_reconstruct.size)\n",
    "        if verbose:\n",
    "            # HINT: This should decrease over multiple iterations. If its not, your code doesn't work right!\n",
    "            # Use this to debug your code!\n",
    "            print('Reconstruction iteration: {}/{} RMSE: {} '.format(n, iterations, diff))\n",
    "    return x_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_amplitudes1 = griffin_lim(true_spec, 2048, 512, 1, verbose=False)\n",
    "display(Audio(rec_amplitudes1, rate=sample_rate))\n",
    "rec_amplitudes2 = griffin_lim(true_spec, 2048, 512, 50, verbose=False)\n",
    "display(Audio(rec_amplitudes2, rate=sample_rate))\n",
    "\n",
    "rec_amplitudes3 = griffin_lim(spec, 2048, 512, 1, verbose=False)\n",
    "display(Audio(rec_amplitudes3, rate=sample_rate))\n",
    "rec_amplitudes4 = griffin_lim(spec, 2048, 512, 50, verbose=False)\n",
    "display(Audio(rec_amplitudes4, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS AN EXAMPLE OF WHAT YOU ARE SUPPORT TO GET\n",
    "# Remember to apply sqrt to spectrogram to get magnitude, note power here.\n",
    "\n",
    "# Let's try this on a real spectrogram\n",
    "ref_amplitudes1 = librosa.griffinlim(np.sqrt(true_spec), n_iter=1, hop_length=512, win_length=2048)\n",
    "display(Audio(ref_amplitudes1, rate=sample_rate))\n",
    "ref_amplitudes2 = librosa.griffinlim(np.sqrt(true_spec), n_iter=50, hop_length=512, win_length=2048)\n",
    "display(Audio(ref_amplitudes2, rate=sample_rate))\n",
    "\n",
    "# Not let's try this on a reconstructed spectrogram\n",
    "ref_amplitudes3 = librosa.griffinlim(np.sqrt(spec), n_iter=1, hop_length=512, win_length=2048)\n",
    "display(Audio(ref_amplitudes3, rate=sample_rate))\n",
    "ref_amplitudes4 = librosa.griffinlim(np.sqrt(spec), n_iter=50, hop_length=512, win_length=2048)\n",
    "display(Audio(ref_amplitudes4, rate=sample_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}